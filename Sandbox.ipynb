{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687234df",
   "metadata": {},
   "source": [
    "### Notebook Description ###\n",
    "Sandbox notebook to play around with some of the code we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a7b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ef4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perspective_api import PerspectiveApiScorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7a0c1",
   "metadata": {},
   "source": [
    "### Perspective API Playground ###\n",
    "\n",
    "Please note this API is rate limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b165e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyDRX9GYuTijhdqk_JF20puTcCR0p2YwCA8\"\n",
    "\n",
    "scorer = PerspectiveApiScorer(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79b457e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxicity': 0.42129645,\n",
       " 'severe_toxicity': 0.014963473,\n",
       " 'sexually_explicit': 0.015569973,\n",
       " 'threat': 0.009204263,\n",
       " 'profanity': 0.11725569,\n",
       " 'identity_attack': 0.06795148}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_scores(\"I strongly dislike you!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd4bb4",
   "metadata": {},
   "source": [
    "### Rewriting model.cond_log_probs() and model.score() ###\n",
    "\n",
    "Unfortunately, the wrapper classes used by their code use the PyTorch version of GPT-2 from hugging face.  The Big Bench tests all use Tensorflow version. \n",
    "\n",
    "The tasks we are interested in (BBQlite, Gender Sensitivity English, and Diverse Social Bias) rely on the cond_log_probs() and score() methods of this wrapper class.  I think we would just need to re-implement these in PyTorch\n",
    "\n",
    "Below are the wrapper classes for gpt2-medium from the Geva paper and from Big Bench. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f42cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_wrappers.gpt2_wrapper import GPT2Wrapper\n",
    "pytorch_gpt2 = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dcdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigbench.models.huggingface_models import _HFTransformerModel, BIGBenchHFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e07ba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bigbench_gpt2 = BIGBenchHFModel(\"gpt2-medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d224e",
   "metadata": {},
   "source": [
    "### Goal ###\n",
    "\n",
    "We want the output from bigbench_gpt2.cond_log_prob() and bigbench_gpt2.score() to match pytorch_gpt.cond_log_prob() and pytorch_gpt.score() respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96b0fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "prompt:\n",
      "What color is the sky? Answer: blue\n",
      "What color is grass? Answer:\n",
      "scores:\n",
      "       red: -1.29\n",
      "      blue: -2.09\n",
      "     green: -0.51\n"
     ]
    }
   ],
   "source": [
    "prompt = (f\"What color is the sky? Answer: blue\\n\" f\"What color is grass? Answer:\")\n",
    "choices =(\"red\", \"blue\", \"green\")\n",
    "\n",
    "scores = bigbench_gpt2.cond_log_prob(inputs=prompts, targets=choices)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"prompt:\\n{prompt}\")\n",
    "print(f\"scores:\")\n",
    "for c, s in zip(choices, scores):\n",
    "    print(f\"  {c:>8}: {s:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37aa02e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10.4252290725708, -11.22307300567627, -9.641101837158203]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs = ['What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:']\n",
    "batch_targets = ['red', 'blue', 'green']\n",
    "bigbench_gpt2._model.score(inputs=batch_inputs, targets=batch_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4acb4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What color is the sky? Answer: blue\n",
      "What color is grass? Answer:\n",
      "red\n",
      "BATCH INPUTS\n",
      "['What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:']\n",
      "BATCH CHOICES\n",
      "['red', 'blue', 'green']\n"
     ]
    }
   ],
   "source": [
    "pytorch_gpt2.cond_log_prob(inputs=prompts, targets=choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58794ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
