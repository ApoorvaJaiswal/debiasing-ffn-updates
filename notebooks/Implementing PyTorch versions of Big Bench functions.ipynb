{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f305f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1ec239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "43f16bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists = [[ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "#           198,  2061,  3124,   318,  8701,    30, 23998,    25,   445],\n",
    "#        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "#           198,  2061,  3124,   318,  8701,    30, 23998,    25, 17585],\n",
    "#        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "#           198,  2061,  3124,   318,  8701,    30, 23998,    25, 14809]]\n",
    "\n",
    "lists = [[ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "          198,  2061,  3124,   318,  8701,    30, 23998,    25],\n",
    "       [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "          198,  2061,  3124,   318,  8701,    30, 23998,    25, 17585],\n",
    "       [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
    "          198,  2061,  3124,   318,  8701,    30, 23998]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a0a21dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Dict, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff919049",
   "metadata": {},
   "source": [
    "\n",
    "### Implement left pad ragged lists ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8b69bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _left_pad_ragged_lists(\n",
    "        ragged_lists: List[List[int]],\n",
    "        pad_value: int,\n",
    "        shape: Optional[Tuple[int, int]] = None,\n",
    "    ) -> np.array:\n",
    "        \"\"\"Pad ragged lists from the left.\n",
    "\n",
    "        Example: [[1,2,3], [4]] -> [[1,2,3], [pad_value, pad_value, 4]]\n",
    "\n",
    "        Args:\n",
    "        ragged_lists: List of lists with unequal lengths.\n",
    "        pad_value: padding token\n",
    "        shape: If None (default) it will padd to the longest element in the\n",
    "            ragged_lists. If not None, it will return a tensor of this shape either\n",
    "            padded or truncated\n",
    "\n",
    "        Returns:\n",
    "        Left padded regular 2D list.\n",
    "        \"\"\"\n",
    "\n",
    "        max_len = max([len(lst) for lst in ragged_lists])\n",
    "        reversed_tensor = torch.tensor([lst[::-1] + [pad_value] * (max_len - len(lst)) for lst in ragged_lists])\n",
    "        padded_tensor = reversed_tensor.flip(dims=(1,))\n",
    "        if shape is not None:\n",
    "            padded_tensor = F.pad(torch.tensor(target_ids), (10,0), 'constant', pad_value)\n",
    "            for d in range(len(shape)):\n",
    "                if padded_tensor.size()[d] > shape[d]:\n",
    "                    padded_tensor = torch.narrow(padded_tensor, d, 0, shape[d])\n",
    "        return padded_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "feb31cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  2061,  3124,   318,   262,  6766,    30, 23998,    25,\n",
       "         4171,   198,  2061,  3124,   318,  8701,    30, 23998,    25],\n",
       "       [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
       "          198,  2061,  3124,   318,  8701,    30, 23998,    25, 17585],\n",
       "       [    0,     0,  2061,  3124,   318,   262,  6766,    30, 23998,\n",
       "           25,  4171,   198,  2061,  3124,   318,  8701,    30, 23998]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_left_pad_ragged_lists(ragged_lists=lists, pad_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d4e943d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _left_pad_constant_length(input, pad_value, length):\n",
    "    return F.pad(torch.tensor(input), (length,0), 'constant', -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "54e5a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,   445],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100, 17585],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100, 14809]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal = [[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
    "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   445],\n",
    "       [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
    "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 17585],\n",
    "       [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
    "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 14809]]\n",
    "_left_pad_constant_length(input=[[445],[17585],[14809]], pad_value=-100, length=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b871f49",
   "metadata": {},
   "source": [
    "### Implement GPT batch tokenize ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a1304c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_wrappers.gpt2_wrapper import GPT2Wrapper\n",
    "pytorch_gpt2 = GPT2Wrapper(model_name = \"gpt2-medium\", use_cuda = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "73b0e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gpt_batch_tokenize(\n",
    "        tokenizer,\n",
    "        batch_inputs: List[str],\n",
    "        batch_targets: Optional[List[str]] = None,\n",
    "        mask_token_id: int = -100,\n",
    "    ) -> Dict[str, np.array]:\n",
    "        \"\"\"Tokenize and prepare batches of input and target string pairs for GPT\n",
    "        (gpt2 or openai-gpt) scoring or generation.\n",
    "\n",
    "        The tokenization requires a pad_token to be defined, and the padding is\n",
    "        done on the left side.\n",
    "\n",
    "        Args:\n",
    "            tokenizer: GPT compatible tokenizer. Assumes it has a defined\n",
    "            pad_token defined.\n",
    "            batch_inputs: List of string inputs\n",
    "            batch_targets: Optional list of string targets. If None (default), the\n",
    "            returned tokenization is equivalent to the targets being empty strings.\n",
    "            mask_token_id: Token id that is used in the returned target_ids to mark\n",
    "            tokens corresponing to the input.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with entries:\n",
    "            inputs_and_targets_ids: token_ids for inputs and targets (concatenated)\n",
    "            targets_ids: Copy of the token_ids for inputs and targets where the\n",
    "                input tokens is masked with mask_token_id.\n",
    "            attention_mask: 0 where input_ids is masked, 1 otherwise.\n",
    "            position_ids: Position ids to account for padding according to the\n",
    "                attention_mask.\n",
    "        \"\"\"\n",
    "\n",
    "        assert tokenizer.pad_token_id is not None, \"Tokenizer must set pad_token_id.\"\n",
    "\n",
    "        ragged_inputs_ids = tokenizer(batch_inputs)[\"input_ids\"]\n",
    "        \n",
    "        if batch_targets:\n",
    "            assert len(batch_inputs) == len(batch_targets), \"Inputs and targets must have the same length.\"\n",
    "            ragged_targets_ids = tokenizer(batch_targets)[\"input_ids\"]\n",
    "        else:\n",
    "            ragged_targets_ids = [[] for _ in batch_inputs]\n",
    "\n",
    "        ragged_inputs_and_targets_ids = [\n",
    "            inp + tar for inp, tar in zip(ragged_inputs_ids, ragged_targets_ids)\n",
    "        ]\n",
    "\n",
    "        inputs_and_targets_ids = _left_pad_ragged_lists(\n",
    "            ragged_lists=ragged_inputs_and_targets_ids, pad_value=tokenizer.pad_token_id\n",
    "        )\n",
    "        \n",
    "        targets_ids = _left_pad_constant_length(\n",
    "            input=ragged_targets_ids,\n",
    "            pad_value=mask_token_id,\n",
    "            length=inputs_and_targets_ids.shape[1]-1,\n",
    "        )\n",
    "\n",
    "        # Infer the values of the attention_mask and position_ids:\n",
    "        attention_mask = inputs_and_targets_ids != tokenizer.pad_token_id\n",
    "        attention_mask = attention_mask.astype(inputs_and_targets_ids.dtype)\n",
    "\n",
    "        position_ids = np.maximum(np.cumsum(attention_mask, axis=-1) - 1, 0)\n",
    "\n",
    "        return {\n",
    "            \"inputs_and_targets_ids\": inputs_and_targets_ids,\n",
    "            \"targets_ids\": targets_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"position_ids\": position_ids,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff6793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs = ['What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:']\n",
    "batch_targets = ['red', 'blue', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d5917569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs_and_targets_ids': array([[ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
       "           198,  2061,  3124,   318,  8701,    30, 23998,    25,   445],\n",
       "        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
       "           198,  2061,  3124,   318,  8701,    30, 23998,    25, 17585],\n",
       "        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,\n",
       "           198,  2061,  3124,   318,  8701,    30, 23998,    25, 14809]]),\n",
       " 'targets_ids': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,   445],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100, 17585],\n",
       "         [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100, 14809]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'position_ids': array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "         16, 17],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "         16, 17],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "         16, 17]])}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gpt_batch_tokenize(\n",
    "    tokenizer=pytorch_gpt2._tokenizer,\n",
    "    batch_inputs=batch_inputs,\n",
    "    batch_targets=batch_targets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054ebac",
   "metadata": {},
   "source": [
    "### Implement Score Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c3753e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyClass:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._model = model\n",
    "        \n",
    "    def score(\n",
    "        self,\n",
    "        inputs: Union[List[str], str],\n",
    "        targets: Union[List[str], str],\n",
    "        mask_token_id=-100,\n",
    "    ) -> List[float]:\n",
    "        \"\"\"Scores one or a batch of example targets given their inputs.\n",
    "        Args:\n",
    "        inputs: input context\n",
    "        targets:  targets to be scored\n",
    "        Returns:\n",
    "        list of log probabilities for each target given the input.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(inputs, str):\n",
    "            input_list = [inputs]\n",
    "            target_list = [targets]\n",
    "        else:\n",
    "            input_list = inputs\n",
    "            target_list = targets\n",
    "\n",
    "        tokenized_ids = _gpt_batch_tokenize(\n",
    "            tokenizer=self._tokenizer,\n",
    "            batch_inputs=input_list,\n",
    "            batch_targets=target_list,\n",
    "        )\n",
    "\n",
    "        inputs_and_targets_ids = torch.tensor(tokenized_ids[\"inputs_and_targets_ids\"])\n",
    "        targets_ids = torch.tensor(tokenized_ids[\"targets_ids\"])\n",
    "        attention_mask = torch.tensor(tokenized_ids[\"attention_mask\"])\n",
    "\n",
    "        print(inputs_and_targets_ids)\n",
    "        print(targets_ids)\n",
    "        print(attention_mask)\n",
    "#         inputs_and_targets_ids = self._maybe_truncate_input(\n",
    "#             inputs_and_targets_ids, verbose=True\n",
    "#         )\n",
    "#         targets_ids = self._maybe_truncate_input(targets_ids, verbose=False)\n",
    "#         attention_mask = self._maybe_truncate_input(attention_mask, verbose=False)\n",
    "        # Calculating position ids, since they might be changed by truncation\n",
    "#         position_ids = torch.maximum(torch.cumsum(attention_mask, axis=-1) - 1, 0)\n",
    "        position_ids = torch.tensor(np.maximum(np.cumsum(attention_mask, axis=-1) - 1, 0))\n",
    "        print(position_ids)\n",
    "        logits = self._model(\n",
    "            inputs_and_targets_ids,\n",
    "            labels=targets_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        ).logits\n",
    "\n",
    "    \n",
    "        return logits\n",
    "\n",
    "#         return logits\n",
    "#         return self.compute_loss(targets_ids, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "12403949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/z1537p3174d8zdjdqg12rhcc0000gn/T/ipykernel_95083/4887656.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets_ids = torch.tensor(tokenized_ids[\"targets_ids\"])\n",
      "/var/folders/6_/z1537p3174d8zdjdqg12rhcc0000gn/T/ipykernel_95083/4887656.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  position_ids = torch.tensor(np.maximum(np.cumsum(attention_mask, axis=-1) - 1, 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,   198,\n",
      "          2061,  3124,   318,  8701,    30, 23998,    25,   445],\n",
      "        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,   198,\n",
      "          2061,  3124,   318,  8701,    30, 23998,    25, 17585],\n",
      "        [ 2061,  3124,   318,   262,  6766,    30, 23998,    25,  4171,   198,\n",
      "          2061,  3124,   318,  8701,    30, 23998,    25, 14809]])\n",
      "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,   445],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100, 17585],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100, 14809]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "toy = ToyClass(tokenizer=pytorch_gpt2._tokenizer, model=pytorch_gpt2._model)\n",
    "logits = toy.score(inputs=batch_inputs, targets=batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c772ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 07:49:39.187344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from bigbench.models.huggingface_models import _HFTransformerModel, BIGBenchHFModel\n",
    "bigbench_gpt2 = BIGBenchHFModel(\"gpt2-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f416e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs = ['What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:', 'What color is the sky? Answer: blue\\nWhat color is grass? Answer:']\n",
    "batch_targets = ['red', 'blue', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5d4d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10.4252290725708, -11.22307300567627, -9.641101837158203]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigbench_gpt2._model.score(inputs=batch_inputs, targets=batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
